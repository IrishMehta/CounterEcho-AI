"""
Vulnerability Assessment Module

This module calculates vulnerability scores for users based on network centrality
and community density metrics.

Community-Camp Mapping:
- RU/CH CAMP: [C3, C7, C21, C12]
- LEFT CAMP: [C25, C10, C1, C5]
- RIGHT CAMP: [C2, C6]
"""

import pandas as pd
import networkx as nx
import logging
from typing import Dict

logger = logging.getLogger(__name__)


class VulnerabilityAssessor:
    """Calculates vulnerability score based on network and narrative metrics."""
    
    def __init__(self, graph: nx.Graph, nodes_df: pd.DataFrame):
        """
        Initialize vulnerability assessor.
        
        Args:
            graph: NetworkX graph (retweet network)
            nodes_df: DataFrame with node_id and community columns
        """
        self.G = graph
        self.nodes_df = nodes_df.set_index('Id') if 'Id' in nodes_df.columns else nodes_df.set_index('node_id')
        
        logger.info("Calculating network metrics...")
        self._calculate_metrics()
        logger.info("Vulnerability Assessor initialized")
    
    def _calculate_metrics(self):
        """Pre-compute network metrics for vulnerability assessment."""
        logger.info("Computing centrality...")
        self.centrality = nx.degree_centrality(self.G)
        
        logger.info("Computing community densities...")
        self.community_density = {}
        for community_id in self.nodes_df['community'].unique():
            members = self.nodes_df[self.nodes_df['community'] == community_id].index.tolist()
            members = [m for m in members if m in self.G]
            if len(members) > 1:
                subgraph = self.G.subgraph(members)
                self.community_density[community_id] = nx.density(subgraph)
            else:
                self.community_density[community_id] = 0.0
        
        logger.debug(f"Computed density for {len(self.community_density)} communities")
    
    def get_vulnerability_score(self, user_id: str) -> float:
        """
        Calculate vulnerability score for a user.
        
        Higher score = more vulnerable (more likely to be persuaded)
        
        Factors:
        - Low centrality -> high vulnerability
        - Low community density -> high vulnerability
        
        Args:
            user_id: User identifier
            
        Returns:
            Vulnerability score (0-1)
        """
        user_id = str(user_id)
        
        if user_id not in self.G:
            logger.error(f"User {user_id} not found in graph")
            raise ValueError(f"User {user_id} not found in graph")
        
        centrality_score = self.centrality.get(user_id, 0)
        max_centrality = max(self.centrality.values()) if self.centrality else 1
        normalized_centrality = centrality_score / max_centrality if max_centrality > 0 else 0
        
        logger.debug(f"User {user_id} centrality: {centrality_score:.4f} (normalized: {normalized_centrality:.4f})")
        
        try:
            community_id = self.nodes_df.loc[user_id, 'community']
            density = self.community_density.get(community_id)
            if density is None:
                logger.error(f"No density found for community {community_id}")
                raise ValueError(f"No density found for community {community_id}")
            logger.debug(f"User {user_id} community {community_id} density: {density:.4f}")
        except KeyError:
            logger.error(f"User {user_id} not found in nodes dataframe")
            raise ValueError(f"User {user_id} not found in nodes dataframe")
        
        vulnerability = ((1 - normalized_centrality) + (1 - density)) / 2
        logger.debug(f"User {user_id} vulnerability score: {vulnerability:.4f}")
        
        return vulnerability

# --- 2. VULNERABILITY ASSESSMENT ---

class VulnerabilityAssessor:
    """Calculates a vulnerability score for users based on network and narrative metrics."""
    
    def __init__(self, G, nodes_df, tweets_df, narrative_definitions):
        self.G = G
        self.nodes_df = nodes_df.set_index('node_id')
        self.tweets_df = tweets_df
        self.narrative_definitions = narrative_definitions
        
        print("Initializing Vulnerability Assessor...")
        self._prepare_data()
        print("Assessor ready.")
        
    def _prepare_data(self):
        """Pre-computes metrics for all users to speed up real-time assessment."""
        print("Pre-computing metrics: narrative matching, centrality, density...")
        
        # Step 2.1: Enhance graph with narrative data
        self._match_tweets_to_narratives()
        
        # Pre-compute metrics
        self.centrality = nx.betweenness_centrality(self.G, k=1000) # Use a sample k for speed
        self._calculate_community_densities()
        self._calculate_narrative_diversity()

    def _match_tweets_to_narratives(self):
        """Creates a mapping of user_id -> list of narratives they engage with."""
        self.user_to_narratives = {}
        # This is a simplified matching process. A real system would be more robust.
        # Flatten narrative definitions for easier searching
        flat_narratives = []
        for camp, data in self.narrative_definitions.items():
            for topic, topic_data in data['topics'].items():
                for label, pattern in topic_data['narratives'].items():
                    # Extract simple keywords from pattern
                    keywords = [kw.strip() for kw in pattern.replace('{', ' ').replace('}', ' ').replace('+', ' ').split(',')]
                    flat_narratives.append({'label': f"{camp.replace(' CAMP','')} | {topic.replace(':','')} | {label}", 'keywords': set(keywords)})
        
        for _, row in self.tweets_df.iterrows():
            user_id = str(row['user_id'])
            content = str(row['content']).lower()
            
            if user_id not in self.user_to_narratives:
                self.user_to_narratives[user_id] = []

            for narrative in flat_narratives:
                # Simple check: if more than 2 keywords match, assign the narrative
                if len([kw for kw in narrative['keywords'] if kw in content]) > 2:
                    self.user_to_narratives[user_id].append(narrative['label'])

    def _calculate_community_densities(self):
        """Calculates the density of each community subgraph."""
        self.community_density = {}
        communities = self.nodes_df['community'].unique()
        for community_id in communities:
            members = self.nodes_df[self.nodes_df['community'] == community_id].index
            subgraph = self.G.subgraph(members)
            self.community_density[community_id] = nx.density(subgraph)

    def _calculate_narrative_diversity(self):
        """Calculates narrative diversity for each user."""
        self.narrative_diversity = {
            user_id: len(set(narratives))
            for user_id, narratives in self.user_to_narratives.items()
        }

    def get_vulnerability_score(self, user_id):
        """Calculates a normalized vulnerability score for a single user."""
        user_id = str(user_id)
        
        # Normalize metrics (0-1 range)
        # Low centrality -> high vulnerability
        max_centrality = max(self.centrality.values()) if self.centrality else 1
        centrality_score = self.centrality.get(user_id, 0) / max_centrality
        
        # High diversity -> high vulnerability
        max_diversity = max(self.narrative_diversity.values()) if self.narrative_diversity else 1
        diversity_score = self.narrative_diversity.get(user_id, 0) / max_diversity
        
        # Low density -> high vulnerability
        try:
            community_id = self.nodes_df.loc[user_id, 'community']
            density_score = self.community_density.get(community_id, 1) # Default to high density (low vuln)
        except KeyError:
            density_score = 1 # User not in a community, assume low vulnerability

        # Combine scores
        vulnerability = ((1 - centrality_score) + diversity_score + (1 - density_score)) / 3
        return vulnerability

# --- 3. STRATEGIC MESSAGING AGENT ---

class CounterEchoAgent:
    """The main agent that processes tweets and determines a strategic response."""
    
    def __init__(self, vulnerability_assessor, narrative_mapping, narrative_definitions):
        self.assessor = vulnerability_assessor
        self.mapping = narrative_mapping
        self.narrative_definitions = narrative_definitions
        # A simple flattened list of narratives for lookups
        self.flat_narratives = self._flatten_narratives()

    def _flatten_narratives(self):
        flat_list = []
        for camp, data in self.narrative_definitions.items():
            for topic, topic_data in data['topics'].items():
                for label, pattern in topic_data['narratives'].items():
                    full_label = f"{camp.replace(' CAMP','')} | {topic.replace(':','')} | {label}"
                    flat_list.append({'full_label': full_label, 'camp': camp, 'pattern': pattern})
        return flat_list
        
    def _get_narrative_from_text(self, text):
        """Placeholder function to detect the narrative of an incoming tweet."""
        # This would be a more sophisticated model in a real system.
        text = text.lower()
        for narrative in self.flat_narratives:
            keywords = [kw.strip() for kw in narrative['pattern'].replace('{', ' ').replace('}', ' ').replace('+', ' ').split(',')]
            if len([kw for kw in keywords if kw in text]) > 2:
                return narrative['full_label']
        return "Unknown Narrative"

    def get_strategic_response(self, user_id, tweet_text, vulnerability_threshold=0.6):
        """The main function to generate a two-step response for a new tweet."""
        
        user_id = str(user_id)
        current_narrative = self._get_narrative_from_text(tweet_text)
        
        if current_narrative == "Unknown Narrative":
            return {"strategy": "No Action", "reason": "Could not identify a known narrative."}
            
        v_score = self.assessor.get_vulnerability_score(user_id)
        
        response = {
            "user_id": user_id,
            "incoming_narrative": current_narrative,
            "vulnerability_score": round(v_score, 3),
        }
        
        # SCENARIO A: VULNERABLE USER
        if v_score > vulnerability_threshold:
            response["strategy"] = "Direct Counter-Narrative"
            counter = self.mapping.get(current_narrative, {}).get("right_camp_counter", "None") # Example: default to right-wing counter
            
            response["counter_narrative"] = counter
            response["step1_message"] = "PLACEHOLDER"
            response["step2_message"] = "PLACEHOLDER"
            response["step1_approach"] = "Directly counter with opposing camp narrative"
            response["step2_approach"] = "Follow up with broader, values-based narrative from the opposing camp (e.g., about 'national security' or 'economic growth')"
        
        # SCENARIO B: NON-VULNERABLE (ENTRENCHED) USER
        else:
            response["strategy"] = "Adjacency Attack (Internal Contradiction)"
            user_camp = current_narrative.split(' | ')[0]
            
            # Find a different, related narrative from the user's OWN camp
            adjacent_narratives = [
                n['full_label'] for n in self.flat_narratives 
                if user_camp in n['full_label'] and n['full_label'] != current_narrative
            ]
            
            adjacent_narrative = "None found"
            if adjacent_narratives:
                adjacent_narrative = random.choice(adjacent_narratives)

            response["adjacent_narrative"] = adjacent_narrative
            response["step1_message"] = "PLACEHOLDER"
            response["step2_message"] = "PLACEHOLDER"
            response["step1_approach"] = "Create cognitive dissonance by showing a related narrative from their OWN camp that contradicts their current position"
            response["step2_approach"] = "Withhold strong propaganda. Offer a softer 'bridging' narrative about an 'all-of-the-above' energy strategy"

        return response

# --- 4. MAIN EXECUTION ---

if __name__ == "__main__":
    # Load all data
    G, nodes, tweets, mapping, definitions = load_all_data()

    if G:
        # Initialize the assessor and the agent
        assessor = VulnerabilityAssessor(G, nodes, tweets, definitions)
        agent = CounterEchoAgent(assessor, mapping, definitions)
        
        # --- SIMULATE NEW TWEETS ---
        
        # Example 1: Left-leaning anti-Russia narrative (potentially vulnerable user)
        # Find a user on the periphery of the graph
        peripheral_user = min(assessor.centrality, key=assessor.centrality.get)
        new_tweet_1 = "Europe must eliminate their reliance on Russian fossil fuels immediately. Putin is using gas as a weapon to fund his barbaric invasion of Ukraine."
        
        # Example 2: Right-leaning pro-fracking narrative (entrenched user)
        # Find a user at the core of the graph
        central_user = max(assessor.centrality, key=assessor.centrality.get)
        new_tweet_2 = "American energy independence through LNG and fracking is the key to national security. We need to expand natural gas production and lift Biden's restrictions."

        # Example 3: Left-leaning anti-IOC narrative (peripheral user)
        try:
            # Find another peripheral user
            sorted_users = sorted(assessor.centrality.items(), key=lambda x: x[1])
            peripheral_user_2 = sorted_users[1][0] if len(sorted_users) > 1 else peripheral_user
        except:
            peripheral_user_2 = peripheral_user
        new_tweet_3 = "Big Oil companies are destroying the planet with their fossil fuel dependence and climate deception. Their greenwashing and renewable rollbacks must stop now."

        # Example 4: Russia/China pro-Russia narrative (entrenched user)
        try:
            sorted_users = sorted(assessor.centrality.items(), key=lambda x: x[1], reverse=True)
            central_user_2 = sorted_users[1][0] if len(sorted_users) > 1 else central_user
        except:
            central_user_2 = central_user
        new_tweet_4 = "Russia is a reliable and vast energy supplier. Europe's continued dependence on Russian gas shows the failure of their so-called energy transition policies."

        print("\n" + "="*50)
        print("PROCESSING SIMULATED TWEETS")
        print("="*50 + "\n")

        # Get and print the strategic response for tweet 1
        print("EXAMPLE 1: Left anti-Russia narrative (vulnerable user)")
        print(f"Tweet: {new_tweet_1}")
        response1 = agent.get_strategic_response(peripheral_user, new_tweet_1)
        print(json.dumps(response1, indent=2))
        
        print("\n" + "-"*50 + "\n")

        # Get and print the strategic response for tweet 2
        print("EXAMPLE 2: Right pro-LNG narrative (entrenched user)")
        print(f"Tweet: {new_tweet_2}")
        response2 = agent.get_strategic_response(central_user, new_tweet_2)
        print(json.dumps(response2, indent=2))

        print("\n" + "-"*50 + "\n")

        # Get and print the strategic response for tweet 3
        print("EXAMPLE 3: Left anti-IOC narrative (vulnerable user)")
        print(f"Tweet: {new_tweet_3}")
        response3 = agent.get_strategic_response(peripheral_user_2, new_tweet_3)
        print(json.dumps(response3, indent=2))

        print("\n" + "-"*50 + "\n")

        # Get and print the strategic response for tweet 4
        print("EXAMPLE 4: Russia/China pro-Russia narrative (entrenched user)")
        print(f"Tweet: {new_tweet_4}")
        response4 = agent.get_strategic_response(central_user_2, new_tweet_4)
        print(json.dumps(response4, indent=2))